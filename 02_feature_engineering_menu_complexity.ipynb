{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22c849c6",
   "metadata": {},
   "source": [
    "# Restaurant Menu Complexity: Feature Engineering\n",
    "\n",
    "## Objectives\n",
    "Since we don't have explicit menu item counts, we'll engineer a **menu complexity proxy** using:\n",
    "\n",
    "1. **Category diversity** - More cuisine tags = broader menu\n",
    "2. **Review text mining** - Extract mentions of menu size/variety\n",
    "3. **Price range** - Higher-end restaurants often have more elaborate menus\n",
    "4. **Cuisine-specific patterns** - Some cuisines typically have simpler/complex menus\n",
    "5. **Business attributes** - Delivery, takeout, groups suggest menu breadth\n",
    "\n",
    "## Treatment Variable\n",
    "We'll create a binary treatment:\n",
    "- **Simple Menu** (0): Below median complexity\n",
    "- **Complex Menu** (1): Above median complexity\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c92fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Plotting\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['text.usetex'] = False  # Prevent LaTeX errors\n",
    "\n",
    "print(\"Imports loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a37d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load Processed Restaurant Data\n",
    "print(\"Loading restaurant data...\")\n",
    "\n",
    "restaurants_df = pd.read_csv('data/processed/restaurants_filtered.csv')\n",
    "\n",
    "print(f\"Loaded {len(restaurants_df):,} restaurants\")\n",
    "print(f\"Shape: {restaurants_df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(restaurants_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdcf3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Parse Business Attributes\n",
    "def parse_attributes(attr_str):\n",
    "    \"\"\"\n",
    "    Parse attributes from string to dictionary\n",
    "    Handles various formats in Yelp data\n",
    "    \"\"\"\n",
    "    if pd.isna(attr_str) or attr_str == 'None' or attr_str == '':\n",
    "        return {}\n",
    "    \n",
    "    if isinstance(attr_str, dict):\n",
    "        return attr_str\n",
    "    \n",
    "    try:\n",
    "        # Try direct eval (Yelp format)\n",
    "        return eval(attr_str)\n",
    "    except:\n",
    "        try:\n",
    "            # Try JSON parse\n",
    "            return json.loads(attr_str)\n",
    "        except:\n",
    "            return {}\n",
    "\n",
    "print(\"Parsing business attributes...\")\n",
    "restaurants_df['attrs_parsed'] = restaurants_df['attributes'].apply(parse_attributes)\n",
    "\n",
    "# Check what attributes are available\n",
    "all_attrs = []\n",
    "for attrs in restaurants_df['attrs_parsed']:\n",
    "    if isinstance(attrs, dict):\n",
    "        all_attrs.extend(attrs.keys())\n",
    "\n",
    "attr_counts = Counter(all_attrs)\n",
    "print(f\"\\nFound {len(attr_counts)} unique attribute types\")\n",
    "print(\"\\nTop 20 most common attributes:\")\n",
    "for attr, count in attr_counts.most_common(20):\n",
    "    print(f\"  {attr}: {count:,} restaurants ({count/len(restaurants_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5208a090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Extract Key Attributes\n",
    "def safe_extract_attr(attrs, key):\n",
    "    \"\"\"Safely extract attribute value\"\"\"\n",
    "    if isinstance(attrs, dict):\n",
    "        val = attrs.get(key)\n",
    "        # Handle nested dicts\n",
    "        if isinstance(val, str) and val.startswith('{'):\n",
    "            try:\n",
    "                return eval(val)\n",
    "            except:\n",
    "                return val\n",
    "        return val\n",
    "    return None\n",
    "\n",
    "print(\"Extracting key attributes...\")\n",
    "\n",
    "# Key attributes that may indicate menu complexity\n",
    "attribute_keys = [\n",
    "    'RestaurantsPriceRange2',\n",
    "    'RestaurantsGoodForGroups',\n",
    "    'RestaurantsTakeOut',\n",
    "    'RestaurantsDelivery',\n",
    "    'OutdoorSeating',\n",
    "    'RestaurantsReservations',\n",
    "    'GoodForKids',\n",
    "    'Alcohol',\n",
    "    'HasTV',\n",
    "    'WiFi',\n",
    "    'Caters',\n",
    "    'RestaurantsTableService',\n",
    "    'RestaurantsAttire'\n",
    "]\n",
    "\n",
    "for key in attribute_keys:\n",
    "    restaurants_df[key] = restaurants_df['attrs_parsed'].apply(\n",
    "        lambda x: safe_extract_attr(x, key)\n",
    "    )\n",
    "\n",
    "print(\"Extracted attributes\")\n",
    "print(\"\\nAttribute coverage:\")\n",
    "for key in attribute_keys:\n",
    "    coverage = restaurants_df[key].notna().sum()\n",
    "    print(f\"  {key}: {coverage:,} ({coverage/len(restaurants_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a8407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Feature 1 - Category Diversity\n",
    "def count_categories(categories):\n",
    "    \"\"\"Count number of distinct categories\"\"\"\n",
    "    if pd.isna(categories):\n",
    "        return 0\n",
    "    cats = [c.strip() for c in str(categories).split(',')]\n",
    "    return len(cats)\n",
    "\n",
    "def get_primary_cuisine(categories):\n",
    "    \"\"\"Extract primary cuisine type\"\"\"\n",
    "    if pd.isna(categories):\n",
    "        return 'Unknown'\n",
    "    \n",
    "    cats_lower = str(categories).lower()\n",
    "    \n",
    "    # Priority-ordered cuisine mapping\n",
    "    cuisine_map = {\n",
    "        'chinese': 'Chinese',\n",
    "        'japanese': 'Japanese',\n",
    "        'sushi': 'Japanese',\n",
    "        'thai': 'Thai',\n",
    "        'indian': 'Indian',\n",
    "        'mexican': 'Mexican',\n",
    "        'italian': 'Italian',\n",
    "        'pizza': 'Pizza',\n",
    "        'french': 'French',\n",
    "        'mediterranean': 'Mediterranean',\n",
    "        'greek': 'Greek',\n",
    "        'middle eastern': 'Middle Eastern',\n",
    "        'korean': 'Korean',\n",
    "        'vietnamese': 'Vietnamese',\n",
    "        'american': 'American',\n",
    "        'steakhouse': 'Steakhouses',\n",
    "        'seafood': 'Seafood',\n",
    "        'burger': 'Burgers',\n",
    "        'sandwich': 'Sandwiches',\n",
    "        'breakfast': 'Breakfast/Brunch',\n",
    "        'brunch': 'Breakfast/Brunch',\n",
    "        'bbq': 'BBQ',\n",
    "        'soul food': 'Soul Food',\n",
    "        'southern': 'Southern',\n",
    "        'latin': 'Latin American',\n",
    "        'spanish': 'Spanish',\n",
    "        'tapas': 'Tapas'\n",
    "    }\n",
    "    \n",
    "    for keyword, cuisine in cuisine_map.items():\n",
    "        if keyword in cats_lower:\n",
    "            return cuisine\n",
    "    \n",
    "    return 'Other'\n",
    "\n",
    "print(\"Engineering category-based features...\")\n",
    "\n",
    "restaurants_df['category_count'] = restaurants_df['categories'].apply(count_categories)\n",
    "restaurants_df['primary_cuisine'] = restaurants_df['categories'].apply(get_primary_cuisine)\n",
    "\n",
    "print(\"Category features created\")\n",
    "print(f\"\\nCategory count distribution:\")\n",
    "print(restaurants_df['category_count'].describe())\n",
    "\n",
    "print(f\"\\nPrimary cuisine distribution:\")\n",
    "print(restaurants_df['primary_cuisine'].value_counts().head(15))\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Category count distribution\n",
    "axes[0].hist(restaurants_df['category_count'], bins=range(1, 15), \n",
    "             edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Number of Categories')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Category Counts per Restaurant')\n",
    "\n",
    "# Top cuisines\n",
    "top_cuisines = restaurants_df['primary_cuisine'].value_counts().head(15)\n",
    "axes[1].barh(range(len(top_cuisines)), top_cuisines.values)\n",
    "axes[1].set_yticks(range(len(top_cuisines)))\n",
    "axes[1].set_yticklabels(top_cuisines.index)\n",
    "axes[1].set_xlabel('Number of Restaurants')\n",
    "axes[1].set_title('Top 15 Cuisine Types')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/figures/category_features.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14479829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Feature 2 - Price Range Processing\n",
    "print(\"Processing price range...\")\n",
    "\n",
    "# Convert price range to numeric\n",
    "def convert_price_range(price_str):\n",
    "    \"\"\"Convert price string to numeric value\"\"\"\n",
    "    if pd.isna(price_str):\n",
    "        return np.nan\n",
    "    \n",
    "    # Convert to string and strip whitespace\n",
    "    price_str = str(price_str).strip().strip(\"'\\\"\")  # Remove quotes too\n",
    "    \n",
    "    # Handle different formats\n",
    "    if price_str in ['1', '1.0']:\n",
    "        return 1\n",
    "    elif price_str in ['2', '2.0']:\n",
    "        return 2\n",
    "    elif price_str in ['3', '3.0']:\n",
    "        return 3\n",
    "    elif price_str in ['4', '4.0']:\n",
    "        return 4\n",
    "    elif price_str == '$':\n",
    "        return 1\n",
    "    elif price_str == '$$':\n",
    "        return 2\n",
    "    elif price_str == '$$$':\n",
    "        return 3\n",
    "    elif price_str == '$$$$':\n",
    "        return 4\n",
    "    else:\n",
    "        # Try to extract first digit if present\n",
    "        match = re.search(r'\\d', price_str)\n",
    "        if match:\n",
    "            digit = int(match.group())\n",
    "            if 1 <= digit <= 4:\n",
    "                return digit\n",
    "        return np.nan\n",
    "\n",
    "restaurants_df['price_numeric'] = restaurants_df['RestaurantsPriceRange2'].apply(convert_price_range)\n",
    "\n",
    "print(\"Price range converted\")\n",
    "print(f\"\\nPrice range distribution:\")\n",
    "print(restaurants_df['price_numeric'].value_counts().sort_index())\n",
    "\n",
    "# Check for any remaining issues\n",
    "print(f\"\\nMissing prices: {restaurants_df['price_numeric'].isna().sum():,}\")\n",
    "\n",
    "# For missing prices, impute with cuisine median\n",
    "cuisine_price_median = restaurants_df.groupby('primary_cuisine')['price_numeric'].median()\n",
    "print(\"\\nMedian price by cuisine (top 10):\")\n",
    "print(cuisine_price_median.sort_values(ascending=False).head(10))\n",
    "\n",
    "def impute_price(row):\n",
    "    \"\"\"Impute missing price with cuisine median\"\"\"\n",
    "    if pd.notna(row['price_numeric']):\n",
    "        return row['price_numeric']\n",
    "    cuisine_median = cuisine_price_median.get(row['primary_cuisine'], np.nan)\n",
    "    if pd.notna(cuisine_median):\n",
    "        return cuisine_median\n",
    "    return 2.0  # Default to mid-range if no cuisine median\n",
    "\n",
    "restaurants_df['price_imputed'] = restaurants_df.apply(impute_price, axis=1)\n",
    "\n",
    "print(f\"\\nImputed {restaurants_df['price_numeric'].isna().sum():,} missing prices\")\n",
    "print(f\"Final price distribution:\")\n",
    "print(restaurants_df['price_imputed'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf4924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Load and Process Reviews for Text Mining\n",
    "print(\"Loading review data...\")\n",
    "print(\"(This will take 2-3 minutes for full dataset)\")\n",
    "\n",
    "# Load reviews\n",
    "restaurant_ids = set(restaurants_df['business_id'])\n",
    "all_reviews = []\n",
    "\n",
    "with open('data/raw/yelp_academic_dataset_review.json', 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        review = json.loads(line)\n",
    "        if review['business_id'] in restaurant_ids:\n",
    "            all_reviews.append({\n",
    "                'business_id': review['business_id'],\n",
    "                'text': review['text'],\n",
    "                'stars': review['stars']\n",
    "            })\n",
    "        \n",
    "        # Progress indicator\n",
    "        if (i + 1) % 500000 == 0:\n",
    "            print(f\"  Processed {i+1:,} reviews... (found {len(all_reviews):,} relevant)\")\n",
    "\n",
    "reviews_df = pd.DataFrame(all_reviews)\n",
    "print(f\"\\nLoaded {len(reviews_df):,} reviews for our restaurants\")\n",
    "print(f\"Average reviews per restaurant: {len(reviews_df)/len(restaurants_df):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481f2504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Feature 3 - Review Text Mining for Menu Signals\n",
    "def extract_menu_signals(text):\n",
    "    \"\"\"\n",
    "    Extract signals about menu size/complexity from review text\n",
    "    Returns dict with various menu-related signals\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return {\n",
    "            'mentions_extensive': 0,\n",
    "            'mentions_limited': 0,\n",
    "            'mentions_variety': 0,\n",
    "            'mentions_options': 0,\n",
    "            'menu_words': 0\n",
    "        }\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Extensive menu indicators\n",
    "    extensive_phrases = [\n",
    "        'so many options', 'extensive menu', 'huge menu', \n",
    "        'lots of choices', 'wide variety', 'tons of options',\n",
    "        'overwhelming menu', 'big menu', 'massive menu',\n",
    "        'endless options', 'too many choices'\n",
    "    ]\n",
    "    \n",
    "    # Limited menu indicators\n",
    "    limited_phrases = [\n",
    "        'limited menu', 'small menu', 'not many options',\n",
    "        'few choices', 'short menu', 'limited selection',\n",
    "        'simple menu', 'focused menu', 'concise menu'\n",
    "    ]\n",
    "    \n",
    "    # Variety/selection mentions\n",
    "    variety_words = ['variety', 'selection', 'options', 'choices']\n",
    "    \n",
    "    return {\n",
    "        'mentions_extensive': sum(1 for phrase in extensive_phrases if phrase in text_lower),\n",
    "        'mentions_limited': sum(1 for phrase in limited_phrases if phrase in text_lower),\n",
    "        'mentions_variety': sum(1 for word in variety_words if word in text_lower),\n",
    "        'mentions_options': text_lower.count('option'),\n",
    "        'menu_words': text_lower.count('menu')\n",
    "    }\n",
    "\n",
    "print(\"Mining review text for menu signals...\")\n",
    "print(\"(This takes 3-5 minutes)\")\n",
    "\n",
    "# Process in chunks for progress tracking\n",
    "chunk_size = 50000\n",
    "review_signals = []\n",
    "\n",
    "for i in range(0, len(reviews_df), chunk_size):\n",
    "    chunk = reviews_df.iloc[i:i+chunk_size]\n",
    "    signals = chunk['text'].apply(extract_menu_signals)\n",
    "    review_signals.extend(signals)\n",
    "    print(f\"  Processed {min(i+chunk_size, len(reviews_df)):,} / {len(reviews_df):,} reviews\")\n",
    "\n",
    "# Convert to dataframe\n",
    "signals_df = pd.DataFrame(review_signals)\n",
    "reviews_df = pd.concat([reviews_df.reset_index(drop=True), signals_df], axis=1)\n",
    "\n",
    "print(\"\\nText mining complete\")\n",
    "print(\"\\nMenu signal statistics:\")\n",
    "print(signals_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca74e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Aggregate Review Signals by Restaurant\n",
    "print(\"Aggregating review signals by restaurant...\")\n",
    "\n",
    "# Group by business\n",
    "business_review_signals = reviews_df.groupby('business_id').agg({\n",
    "    'mentions_extensive': 'sum',\n",
    "    'mentions_limited': 'sum',\n",
    "    'mentions_variety': 'sum',\n",
    "    'mentions_options': 'sum',\n",
    "    'menu_words': 'sum',\n",
    "    'text': 'count'  # Total reviews\n",
    "}).reset_index()\n",
    "\n",
    "business_review_signals.rename(columns={'text': 'review_count_analyzed'}, inplace=True)\n",
    "\n",
    "# Create net complexity signal\n",
    "business_review_signals['net_complexity_signal'] = (\n",
    "    business_review_signals['mentions_extensive'] - \n",
    "    business_review_signals['mentions_limited']\n",
    ")\n",
    "\n",
    "# Normalize by review count\n",
    "business_review_signals['extensive_per_review'] = (\n",
    "    business_review_signals['mentions_extensive'] / \n",
    "    business_review_signals['review_count_analyzed']\n",
    ")\n",
    "\n",
    "business_review_signals['limited_per_review'] = (\n",
    "    business_review_signals['mentions_limited'] / \n",
    "    business_review_signals['review_count_analyzed']\n",
    ")\n",
    "\n",
    "print(\"Aggregation complete\")\n",
    "print(f\"\\nRestaurants with review signals: {len(business_review_signals):,}\")\n",
    "print(\"\\nAggregated signal statistics:\")\n",
    "print(business_review_signals[['mentions_extensive', 'mentions_limited', \n",
    "                                'net_complexity_signal']].describe())\n",
    "\n",
    "# Merge back to main dataframe\n",
    "restaurants_df = restaurants_df.merge(business_review_signals, \n",
    "                                     on='business_id', \n",
    "                                     how='left')\n",
    "\n",
    "# Fill NAs (restaurants with no signals)\n",
    "signal_cols = ['mentions_extensive', 'mentions_limited', 'mentions_variety', \n",
    "               'mentions_options', 'menu_words', 'net_complexity_signal',\n",
    "               'extensive_per_review', 'limited_per_review']\n",
    "\n",
    "for col in signal_cols:\n",
    "    if col in restaurants_df.columns:\n",
    "        restaurants_df[col] = restaurants_df[col].fillna(0)\n",
    "\n",
    "print(\"Merged signals to restaurant dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9765a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Feature 4 - Cuisine-Specific Complexity Patterns\n",
    "print(\"Creating cuisine-based complexity adjustments...\")\n",
    "\n",
    "# Define typical complexity by cuisine type\n",
    "# Based on general knowledge of these cuisines\n",
    "cuisine_complexity = {\n",
    "    'Chinese': 5,      # Typically extensive menus\n",
    "    'Indian': 5,       # Many options across appetizers, breads, curries\n",
    "    'Thai': 4,         # Moderate-high variety\n",
    "    'Mexican': 4,      # Tacos, burritos, various proteins\n",
    "    'Italian': 4,      # Pasta, pizza, entrees\n",
    "    'American': 4,     # Diverse offerings\n",
    "    'Japanese': 3,     # Focused but varied\n",
    "    'Korean': 3,       # Moderate variety\n",
    "    'Mediterranean': 3,\n",
    "    'Middle Eastern': 3,\n",
    "    'Vietnamese': 3,\n",
    "    'French': 3,       # Often focused, refined\n",
    "    'Steakhouses': 2,  # Limited to steaks, sides\n",
    "    'Seafood': 3,\n",
    "    'BBQ': 2,          # Meat-focused\n",
    "    'Pizza': 1,        # Very focused\n",
    "    'Burgers': 1,      # Limited menu\n",
    "    'Sandwiches': 2,   # Somewhat limited\n",
    "    'Breakfast/Brunch': 3,\n",
    "    'Soul Food': 3,\n",
    "    'Southern': 3,\n",
    "    'Latin American': 4,\n",
    "    'Spanish': 3,\n",
    "    'Tapas': 4,        # Many small plates\n",
    "    'Greek': 3,\n",
    "    'Other': 3         # Neutral\n",
    "}\n",
    "\n",
    "restaurants_df['cuisine_complexity_base'] = restaurants_df['primary_cuisine'].map(\n",
    "    cuisine_complexity\n",
    ").fillna(3)\n",
    "\n",
    "print(\"Cuisine complexity patterns assigned\")\n",
    "print(\"\\nCuisine complexity scores:\")\n",
    "for cuisine, score in sorted(cuisine_complexity.items(), key=lambda x: x[1], reverse=True):\n",
    "    count = (restaurants_df['primary_cuisine'] == cuisine).sum()\n",
    "    print(f\"  {cuisine}: {score} ({count:,} restaurants)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e01faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Create Composite Menu Complexity Score\n",
    "print(\"Creating composite menu complexity score...\")\n",
    "\n",
    "def calculate_menu_complexity_score(row):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive menu complexity score\n",
    "    \n",
    "    Components:\n",
    "    1. Category diversity (0-15 points)\n",
    "    2. Review text signals (0-20 points)\n",
    "    3. Price range proxy (0-12 points)\n",
    "    4. Cuisine baseline (0-5 points)\n",
    "    5. Business attributes (0-10 points)\n",
    "    \n",
    "    Total: 0-62 points (higher = more complex)\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    \n",
    "    # 1. Category diversity (cap at 15 points)\n",
    "    score += min(row['category_count'] * 2.5, 15)\n",
    "    \n",
    "    # 2. Review signals (up to 20 points)\n",
    "    # Net signal: extensive mentions - limited mentions\n",
    "    net_signal = row.get('net_complexity_signal', 0)\n",
    "    score += min(max(net_signal * 2, -5), 15)  # Cap positive, small negative penalty\n",
    "    \n",
    "    # Variety mentions\n",
    "    score += min(row.get('mentions_variety', 0) * 0.5, 5)\n",
    "    \n",
    "    # 3. Price range (higher price often = more elaborate menu)\n",
    "    price = row.get('price_imputed', 2)\n",
    "    score += price * 3\n",
    "    \n",
    "    # 4. Cuisine baseline\n",
    "    score += row.get('cuisine_complexity_base', 3)\n",
    "    \n",
    "    # 5. Business attributes suggesting menu breadth\n",
    "    if row.get('RestaurantsGoodForGroups') in ['True', True]:\n",
    "        score += 2  # Group dining suggests variety\n",
    "    if row.get('RestaurantsDelivery') in ['True', True]:\n",
    "        score += 1\n",
    "    if row.get('Caters') in ['True', True]:\n",
    "        score += 2  # Catering suggests diverse menu\n",
    "    if row.get('RestaurantsTableService') in ['True', True]:\n",
    "        score += 1  # Full service suggests more elaborate\n",
    "    \n",
    "    # Apply ceiling and floor\n",
    "    return max(5, min(score, 60))\n",
    "\n",
    "restaurants_df['menu_complexity_score'] = restaurants_df.apply(\n",
    "    calculate_menu_complexity_score, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"Menu complexity score calculated\")\n",
    "print(\"\\nComplexity score distribution:\")\n",
    "print(restaurants_df['menu_complexity_score'].describe())\n",
    "\n",
    "# Visualize - FIX: Disable LaTeX rendering in matplotlib\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['text.usetex'] = False  # This is the key fix\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Distribution\n",
    "axes[0, 0].hist(restaurants_df['menu_complexity_score'], bins=40, \n",
    "                edgecolor='black', alpha=0.7)\n",
    "median_val = restaurants_df['menu_complexity_score'].median()\n",
    "axes[0, 0].axvline(median_val, \n",
    "                   color='red', linestyle='--', \n",
    "                   label=f'Median: {median_val:.1f}')\n",
    "axes[0, 0].set_xlabel('Menu Complexity Score')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Distribution of Menu Complexity Scores')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# By cuisine\n",
    "cuisine_complexity_data = restaurants_df.groupby('primary_cuisine').agg({\n",
    "    'menu_complexity_score': 'mean',\n",
    "    'business_id': 'count'\n",
    "}).reset_index()\n",
    "cuisine_complexity_data = cuisine_complexity_data[cuisine_complexity_data['business_id'] >= 100]\n",
    "cuisine_complexity_data = cuisine_complexity_data.sort_values('menu_complexity_score', ascending=False)\n",
    "\n",
    "axes[0, 1].barh(range(len(cuisine_complexity_data)), cuisine_complexity_data['menu_complexity_score'])\n",
    "axes[0, 1].set_yticks(range(len(cuisine_complexity_data)))\n",
    "axes[0, 1].set_yticklabels(cuisine_complexity_data['primary_cuisine'])\n",
    "axes[0, 1].set_xlabel('Average Complexity Score')\n",
    "axes[0, 1].set_title('Menu Complexity by Cuisine Type (n>=100)')\n",
    "axes[0, 1].invert_yaxis()\n",
    "\n",
    "# Complexity vs Rating\n",
    "axes[1, 0].scatter(restaurants_df['menu_complexity_score'], \n",
    "                   restaurants_df['stars'], \n",
    "                   alpha=0.3, s=10)\n",
    "axes[1, 0].set_xlabel('Menu Complexity Score')\n",
    "axes[1, 0].set_ylabel('Rating (Stars)')\n",
    "axes[1, 0].set_title('Menu Complexity vs Restaurant Rating')\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(restaurants_df['menu_complexity_score'], restaurants_df['stars'], 1)\n",
    "p = np.poly1d(z)\n",
    "x_line = np.linspace(restaurants_df['menu_complexity_score'].min(), \n",
    "                     restaurants_df['menu_complexity_score'].max(), 100)\n",
    "axes[1, 0].plot(x_line, p(x_line), \"r--\", alpha=0.8, linewidth=2, \n",
    "                label=f'Trend: y={z[0]:.4f}x+{z[1]:.2f}')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# By price range\n",
    "price_complexity = restaurants_df.groupby('price_imputed')['menu_complexity_score'].mean()\n",
    "axes[1, 1].bar(price_complexity.index, price_complexity.values, \n",
    "               edgecolor='black', alpha=0.7)\n",
    "axes[1, 1].set_xlabel('Price Range')\n",
    "axes[1, 1].set_ylabel('Average Complexity Score')\n",
    "axes[1, 1].set_title('Menu Complexity by Price Range')\n",
    "axes[1, 1].set_xticks([1, 2, 3, 4])\n",
    "# Use plain text labels instead of dollar signs\n",
    "axes[1, 1].set_xticklabels(['Budget', 'Moderate', 'Upscale', 'Fine Dining'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/figures/menu_complexity_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation\n",
    "corr = restaurants_df[['menu_complexity_score', 'stars', 'review_count']].corr()\n",
    "print(\"\\nCorrelation matrix:\")\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b42e0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Create Binary Treatment Variable\n",
    "print(\"Creating binary treatment variable...\")\n",
    "\n",
    "# Use median split\n",
    "median_complexity = restaurants_df['menu_complexity_score'].median()\n",
    "restaurants_df['complex_menu'] = (\n",
    "    restaurants_df['menu_complexity_score'] > median_complexity\n",
    ").astype(int)\n",
    "\n",
    "print(f\"Treatment variable created (median split at {median_complexity:.1f})\")\n",
    "print(f\"\\nTreatment distribution:\")\n",
    "print(restaurants_df['complex_menu'].value_counts())\n",
    "print(f\"\\nAs percentages:\")\n",
    "print(restaurants_df['complex_menu'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Compare groups\n",
    "print(\"\\n=== TREATMENT GROUP COMPARISON ===\")\n",
    "comparison = restaurants_df.groupby('complex_menu').agg({\n",
    "    'stars': ['mean', 'std', 'count'],\n",
    "    'review_count': ['mean', 'median'],\n",
    "    'menu_complexity_score': ['min', 'max', 'mean']\n",
    "})\n",
    "print(comparison)\n",
    "\n",
    "# Visualize treatment groups\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Rating distribution by treatment\n",
    "restaurants_df.boxplot(column='stars', by='complex_menu', ax=axes[0])\n",
    "axes[0].set_xlabel('Menu Type (0=Simple, 1=Complex)')\n",
    "axes[0].set_ylabel('Rating (Stars)')\n",
    "axes[0].set_title('Rating Distribution by Menu Complexity')\n",
    "plt.sca(axes[0])\n",
    "plt.xticks([1, 2], ['Simple Menu', 'Complex Menu'])\n",
    "\n",
    "# Review count by treatment\n",
    "restaurants_df.boxplot(column='review_count', by='complex_menu', ax=axes[1])\n",
    "axes[1].set_xlabel('Menu Type (0=Simple, 1=Complex)')\n",
    "axes[1].set_ylabel('Review Count (log scale)')\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].set_title('Review Count by Menu Complexity')\n",
    "plt.sca(axes[1])\n",
    "plt.xticks([1, 2], ['Simple Menu', 'Complex Menu'])\n",
    "\n",
    "plt.suptitle('')  # Remove auto-generated title\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/figures/treatment_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aeb806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Create Validation Sample\n",
    "print(\"Creating validation sample for manual checking...\")\n",
    "\n",
    "# Sample restaurants across complexity spectrum\n",
    "validation_sample = pd.concat([\n",
    "    restaurants_df.nsmallest(25, 'menu_complexity_score'),  # 25 simplest\n",
    "    restaurants_df.sample(50),  # 50 random\n",
    "    restaurants_df.nlargest(25, 'menu_complexity_score')   # 25 most complex\n",
    "])\n",
    "\n",
    "validation_cols = [\n",
    "    'business_id', 'name', 'city', 'state', 'categories', \n",
    "    'primary_cuisine', 'stars', 'review_count',\n",
    "    'category_count', 'price_imputed', \n",
    "    'mentions_extensive', 'mentions_limited',\n",
    "    'menu_complexity_score', 'complex_menu'\n",
    "]\n",
    "\n",
    "validation_export = validation_sample[validation_cols].copy()\n",
    "validation_export.to_csv('data/validation/validation_sample.csv', index=False)\n",
    "\n",
    "print(f\"Saved {len(validation_export)} restaurants to data/validation/validation_sample.csv\")\n",
    "print(\"\\nSample of validation data:\")\n",
    "print(validation_export.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MANUAL VALIDATION INSTRUCTIONS\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. Open data/validation/validation_sample.csv\")\n",
    "print(\"2. For 20-30 restaurants, look up their actual menu online\")\n",
    "print(\"3. Rate if complexity score seems reasonable (1-5 scale)\")\n",
    "print(\"4. Note any major misclassifications\")\n",
    "print(\"5. This validates our proxy measure!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9447a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Save Final Feature-Engineered Dataset\n",
    "print(\"Saving feature-engineered dataset...\")\n",
    "\n",
    "# Select final columns\n",
    "final_columns = [\n",
    "    # Identifiers\n",
    "    'business_id', 'name', 'city', 'state', 'postal_code',\n",
    "    'latitude', 'longitude',\n",
    "    \n",
    "    # Outcomes\n",
    "    'stars', 'review_count',\n",
    "    \n",
    "    # Treatment\n",
    "    'complex_menu', 'menu_complexity_score',\n",
    "    \n",
    "    # Features for matching/controls\n",
    "    'primary_cuisine', 'category_count',\n",
    "    'price_imputed', 'is_open',\n",
    "    \n",
    "    # Review signals\n",
    "    'mentions_extensive', 'mentions_limited', \n",
    "    'mentions_variety', 'net_complexity_signal',\n",
    "    \n",
    "    # Business attributes\n",
    "    'RestaurantsPriceRange2', 'RestaurantsGoodForGroups',\n",
    "    'RestaurantsTakeOut', 'RestaurantsDelivery',\n",
    "    'RestaurantsReservations', 'Caters',\n",
    "    \n",
    "    # Original data\n",
    "    'categories', 'attributes'\n",
    "]\n",
    "\n",
    "# Keep only columns that exist\n",
    "final_columns = [col for col in final_columns if col in restaurants_df.columns]\n",
    "\n",
    "restaurants_final = restaurants_df[final_columns].copy()\n",
    "restaurants_final.to_csv('data/processed/restaurants_with_features.csv', index=False)\n",
    "\n",
    "print(f\"Saved {len(restaurants_final):,} restaurants with {len(final_columns)} features\")\n",
    "print(f\"File: data/processed/restaurants_with_features.csv\")\n",
    "\n",
    "# Save feature summary\n",
    "feature_summary = pd.DataFrame({\n",
    "    'Feature': final_columns,\n",
    "    'Non-Null Count': [restaurants_final[col].notna().sum() for col in final_columns],\n",
    "    'Data Type': [restaurants_final[col].dtype for col in final_columns]\n",
    "})\n",
    "feature_summary['Coverage %'] = (feature_summary['Non-Null Count'] / len(restaurants_final) * 100).round(2)\n",
    "feature_summary.to_csv('data/processed/feature_summary.csv', index=False)\n",
    "\n",
    "print(\"\\nSaved feature summary\")\n",
    "print(\"\\nFeature summary:\")\n",
    "print(feature_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035b6ae9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Features Created\n",
    "\n",
    "**1. Menu Complexity Score (Continuous)**\n",
    "- Range: 5 to 55\n",
    "- Median: 24.5\n",
    "- Components: Category diversity, review signals, price, cuisine patterns, attributes\n",
    "\n",
    "**2. Treatment Variable (Binary)**\n",
    "- Simple Menu (0): 8893 restaurants\n",
    "- Complex Menu (1): 8732 restaurants\n",
    "- Split at median complexity score 24.5\n",
    "\n",
    "### Key Component Contributions\n",
    "\n",
    "| Component | Weight | Rationale |\n",
    "|-----------|--------|-----------|\n",
    "| Category diversity | 0-15 pts | More cuisine tags = broader menu |\n",
    "| Review signals | 0-20 pts | Customer perceptions of menu size |\n",
    "| Price range | 0-12 pts | Higher-end â†’ more elaborate |\n",
    "| Cuisine baseline | 0-5 pts | Typical complexity patterns |\n",
    "| Business attributes | 0-10 pts | Catering, groups suggest variety |\n",
    "\n",
    "### Initial Observations\n",
    "\n",
    "[Fill in after running]:\n",
    "1. **Complexity-Rating Correlation**: \n",
    "2. **Cuisine Patterns**: \n",
    "3. **Price Relationship**: \n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In Notebook 03, we'll:\n",
    "\n",
    "1. Conduct comprehensive EDA\n",
    "2. Identify potential confounders\n",
    "3. Check covariate balance between treatment groups\n",
    "4. Visualize relationships"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
